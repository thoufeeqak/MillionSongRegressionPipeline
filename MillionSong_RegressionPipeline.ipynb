{"cells":[{"cell_type":"markdown","source":["###  Load and check the data"],"metadata":{}},{"cell_type":"code","source":["import os.path\nfile_name = os.path.join('databricks-datasets', 'cs190', 'data-001', 'millionsong.txt')\n\nraw_data_df = sqlContext.read.load(file_name, 'text')"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["num_points = raw_data_df.count()\nprint num_points\nsample_points = raw_data_df.take(5)\nprint sample_points"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["from pyspark.mllib.regression import LabeledPoint\nimport numpy as np\nimport pyspark.sql.functions"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["from pyspark.sql import functions as sql_functions\n\ndef parse_points(df):\n    \n    \"\"\"Converts a DataFrame of comma separated unicode strings into a DataFrame of `LabeledPoints`.\n    \n\n    Args:\n        df: DataFrame where each row is a comma separated unicode string. The first element in the string\n            is the label and the remaining elements are the features.\n\n    Returns:\n        DataFrame: Each row is converted into a `LabeledPoint`, which consists of a label and\n            features. To convert an RDD to a DataFrame, simply call toDF().\n    \"\"\"\n    return df.select(sql_functions.split(df.value,',').alias('values')).map(lambda x:LabeledPoint(x['values'][0],x['values'][1:])).toDF()\n    \n\n  \nparsed_points_df = parse_points(raw_data_df)\nfirst_point_features = parsed_points_df.first().features\nfirst_point_label = parsed_points_df.first().label\nprint first_point_features, first_point_label\nd = len(first_point_features)\nprint d"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Visualization"],"metadata":{}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\n\n# takeSample(withReplacement, num, [seed]) randomly selects num elements from the dataset with/without replacement, and has an\n# optional seed parameter that one can set for reproducible results\n\ndata_values = (parsed_points_df\n               .rdd\n               .map(lambda lp: lp.features.toArray())\n               .takeSample(False, 50, 47))\n\ndef prepare_plot(xticks, yticks, figsize=(10.5, 6), hideLabels=False, gridColor='#999999',\n                 gridWidth=1.0):\n    \"\"\"Template for generating the plot layout.\"\"\"\n    plt.close()\n    fig, ax = plt.subplots(figsize=figsize, facecolor='white', edgecolor='white')\n    ax.axes.tick_params(labelcolor='#999999', labelsize='10')\n    for axis, ticks in [(ax.get_xaxis(), xticks), (ax.get_yaxis(), yticks)]:\n        axis.set_ticks_position('none')\n        axis.set_ticks(ticks)\n        axis.label.set_color('#999999')\n        if hideLabels: axis.set_ticklabels([])\n    plt.grid(color=gridColor, linewidth=gridWidth, linestyle='-')\n    map(lambda position: ax.spines[position].set_visible(False), ['bottom', 'top', 'left', 'right'])\n    return fig, ax\n\n# generate layout and plot\nfig, ax = prepare_plot(np.arange(.5, 11, 1), np.arange(.5, 49, 1), figsize=(8,7), hideLabels=True,\n                       gridColor='#eeeeee', gridWidth=1.1)\nimage = plt.imshow(data_values,interpolation='nearest', aspect='auto', cmap=cm.Greys)\nfor x, y, s in zip(np.arange(-.125, 12, 1), np.repeat(-.75, 12), [str(x) for x in range(12)]):\n    plt.text(x, y, s, color='#999999', size='10')\nplt.text(4.7, -3, 'Feature', color='#999999', size='11'), ax.set_ylabel('Observation')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["content_stats = (parsed_points_df\n                 .selectExpr(\"min(label)\",\"max(label)\")\n                .collect())\nmin_year = content_stats[0][\"min(label)\"]\nmax_year = content_stats[0][\"max(label)\"]\n\nprint min_year, max_year\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["### Shift labels"],"metadata":{}},{"cell_type":"code","source":["parsed_data_df = parsed_points_df.select(parsed_points_df.features,parsed_points_df.label-min_year).withColumnRenamed('(label - 1922.0)', 'label')\n\n# View the first point\nprint '\\n{0}'.format(parsed_data_df.first())"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["# get data for plot\nold_data = (parsed_points_df\n             .rdd\n             .map(lambda lp: (lp.label, 1))\n             .reduceByKey(lambda x, y: x + y)\n             .collect())\nx, y = zip(*old_data)\n\n# generate layout and plot data\nfig, ax = prepare_plot(np.arange(1920, 2050, 20), np.arange(0, 150, 20))\nplt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\nax.set_xlabel('Year'), ax.set_ylabel('Count')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["# get data for plot\nnew_data = (parsed_points_df\n             .rdd\n             .map(lambda lp: (lp.label, 1))\n             .reduceByKey(lambda x, y: x + y)\n             .collect())\nx, y = zip(*new_data)\n\n# generate layout and plot data\nfig, ax = prepare_plot(np.arange(0, 120, 20), np.arange(0, 120, 20))\nplt.scatter(x, y, s=14**2, c='#d6ebf2', edgecolors='#8cbfd0', alpha=0.75)\nax.set_xlabel('Year (shifted)'), ax.set_ylabel('Count')\ndisplay(fig)\npass"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["###Training, validation, and test sets"],"metadata":{}},{"cell_type":"code","source":["weights = [.8, .1, .1]\nseed = 42\nparsed_train_data_df, parsed_val_data_df, parsed_test_data_df = parsed_data_df.randomSplit(weights,seed)\nparsed_train_data_df.cache()\nparsed_val_data_df.cache()\nparsed_test_data_df.cache()\nn_train = parsed_train_data_df.count()\nn_val = parsed_val_data_df.count()\nn_test = parsed_test_data_df.count()\n\nprint n_train, n_val, n_test, n_train + n_val + n_test\nprint parsed_data_df.count()"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["## Create and evaluate a baseline model"],"metadata":{}},{"cell_type":"code","source":["average_train_year = (parsed_train_data_df\n                        .selectExpr(\"avg(label)\").first()[0])\nprint average_train_year"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Root mean squared error"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import RegressionEvaluator\n\npreds_and_labels = [(1., 3.), (2., 1.), (2., 2.)]\npreds_and_labels_df = sqlContext.createDataFrame(preds_and_labels, [\"prediction\", \"label\"])\n\nevaluator = RegressionEvaluator(predictionCol=\"prediction\")\ndef calc_RMSE(dataset):\n    \"\"\"Calculates the root mean squared error for an dataset of (prediction, label) tuples.\n\n    Args:\n        dataset (DataFrame of (float, float)): A `DataFrame` consisting of (prediction, label) tuples.\n\n    Returns:\n        float: The square root of the mean of the squared errors.\n    \"\"\"\n    return evaluator.evaluate(dataset,{evaluator.metricName: \"rmse\"})\n\nexample_rmse = calc_RMSE(preds_and_labels_df)\nprint example_rmse\n# RMSE = sqrt[((1-3)^2 + (2-1)^2 + (2-2)^2) / 3] = 1.291"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["### Training, validation and test RMSE"],"metadata":{}},{"cell_type":"code","source":["preds_and_labels_train = parsed_train_data_df.map(lambda l:(average_train_year,l.label)).toDF()\npreds_and_labels_train"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":["### Visualization: Predicted vs. actual"],"metadata":{}},{"cell_type":"code","source":["from matplotlib.colors import ListedColormap, Normalize\nfrom matplotlib.cm import get_cmap\ncmap = get_cmap('YlOrRd')\nnorm = Normalize()\n\ndef squared_error(label, prediction):\n    \"\"\"Calculates the squared error for a single prediction.\"\"\"\n    return float((label - prediction)**2)\n\nactual = np.asarray(parsed_val_data_df\n                    .select('label')\n                    .collect())\nerror = np.asarray(parsed_val_data_df\n                   .rdd\n                   .map(lambda lp: (lp.label, lp.label))\n                   .map(lambda (l, p): squared_error(l, p))\n                   .collect())\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\nfig, ax = prepare_plot(np.arange(0, 100, 20), np.arange(0, 100, 20))\nplt.scatter(actual, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.5)\nax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["def squared_error(label, prediction):\n    \"\"\"Calculates the squared error for a single prediction.\"\"\"\n    return float((label - prediction)**2)\n\npredictions = np.asarray(parsed_val_data_df\n                         .rdd\n                         .map(lambda lp: average_train_year)\n                         .collect())\nerror = np.asarray(parsed_val_data_df\n                   .rdd\n                   .map(lambda lp: (average_train_year, lp.label))\n                   .map(lambda (l, p): squared_error(l, p))\n                   .collect())\nnorm = Normalize()\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\n\nfig, ax = prepare_plot(np.arange(53.0, 55.0, 0.5), np.arange(0, 100, 20))\nax.set_xlim(53, 55)\nplt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=0.3)\nax.set_xlabel('Predicted'), ax.set_ylabel('Actual')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":["## Train (via gradient descent) and evaluate a linear regression model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.mllib.linalg import DenseVector"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["\ndef gradient_summand(weights, lp):\n    \"\"\"Calculates the gradient summand for a given weight and `LabeledPoint`.\n\n    Note:\n        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n        within this function.  For example, they both implement the `dot` method.\n\n    Args:\n        weights (DenseVector): An array of model weights (betas).\n        lp (LabeledPoint): The `LabeledPoint` for a single observation.\n\n    Returns:\n        DenseVector: An array of values the same length as `weights`.  The gradient summand.\n    \"\"\"\n    return (weights.dot(lp.features)-lp.label)*(lp.features)\n\nexample_w = DenseVector([1, 1, 1])\nexample_lp = LabeledPoint(2.0, [3, 1, 4])\n# gradient_summand = (dot([1 1 1], [3 1 4]) - 2) * [3 1 4] = (8 - 2) * [3 1 4] = [18 6 24]\nsummand_one = gradient_summand(example_w, example_lp)\nprint summand_one\n\nexample_w = DenseVector([.24, 1.2, -1.4])\nexample_lp = LabeledPoint(3.0, [-1.4, 4.2, 2.1])\nsummand_two = gradient_summand(example_w, example_lp)\nprint summand_two"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["###  Using weights to make predictions"],"metadata":{}},{"cell_type":"code","source":["def get_labeled_prediction(weights, observation):\n    \"\"\"Calculates predictions and returns a (prediction, label) tuple.\n\n    Note:\n        The labels should remain unchanged as we'll use this information to calculate prediction\n        error later.\n\n    Args:\n        weights (np.ndarray): An array with one weight for each features in `trainData`.\n        observation (LabeledPoint): A `LabeledPoint` that contain the correct label and the\n            features for the data point.\n\n    Returns:\n        tuple: A (prediction, label) tuple. Convert the return type of the label and prediction to a float.\n    \"\"\"\n    tem= weights.dot(observation.features)\n    return (float(tem),float(observation.label))\n\nweights = np.array([1.0, 1.5])\nprediction_example = sc.parallelize([LabeledPoint(2, np.array([1.0, .5])),\n                                     LabeledPoint(1.5, np.array([.5, .5]))])\npreds_and_labels_example = prediction_example.map(lambda lp: get_labeled_prediction(weights, lp))\nprint preds_and_labels_example.collect()\n"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":["###  Gradient descent\n\nNext, implement a gradient descent function for linear regression and test out this function on an example."],"metadata":{}},{"cell_type":"code","source":["def linreg_gradient_descent(train_data, num_iters):\n    \"\"\"Calculates the weights and error for a linear regression model trained with gradient descent.\n\n    Note:\n        `DenseVector` behaves similarly to a `numpy.ndarray` and they can be used interchangably\n        within this function.  For example, they both implement the `dot` method.\n\n    Args:\n        train_data (RDD of LabeledPoint): The labeled data for use in training the model.\n        num_iters (int): The number of iterations of gradient descent to perform.\n\n    Returns:\n        (np.ndarray, np.ndarray): A tuple of (weights, training errors).  Weights will be the\n            final weights (one weight per feature) for the model, and training errors will contain\n            an error (RMSE) for each iteration of the algorithm.\n    \"\"\"\n    # The length of the training data\n    n = train_data.count()\n    # The number of features in the training data\n    d = len(train_data.first().features)\n    w = np.zeros(d)\n    alpha = 1.0\n    # We will compute and store the training error after each iteration\n    error_train = np.zeros(num_iters)\n    for i in range(num_iters):\n        # Use get_labeled_prediction from (3b) with trainData to obtain an RDD of (label, prediction)\n        # tuples.  Note that the weights all equal 0 for the first iteration, so the predictions will\n        # have large errors to start.\n        preds_and_labels_train = train_data.map(lambda l:get_labeled_prediction(w,l))\n        preds_and_labels_train_df = sqlContext.createDataFrame(preds_and_labels_train, [\"prediction\", \"label\"])\n        error_train[i] = calc_RMSE(preds_and_labels_train_df)\n\n        # Calculate the `gradient`.  Make use of the `gradient_summand` function you wrote in (3a).\n        # Note that `gradient` should be a `DenseVector` of length `d`.\n        gradient = train_data.map(lambda l:gradient_summand(w,l)).sum()\n\n        # Update the weights\n        alpha_i = alpha / (n * np.sqrt(i+1))\n        w -= alpha_i*gradient\n    return w, error_train\n\n"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["###  Train the model"],"metadata":{}},{"cell_type":"code","source":["num_iters = 50\nweights_LR0, error_train_LR0 = linreg_gradient_descent(parsed_train_data_df,num_iters)\n\npreds_and_labels = (parsed_val_data_df\n                      .map(lambda l:get_labeled_prediction(weights_LR0,l)))\npreds_and_labels_df = sqlContext.createDataFrame(preds_and_labels, [\"prediction\", \"label\"])\nrmse_val_LR0 = calc_RMSE(preds_and_labels_df)\n\nprint 'Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}'.format(rmse_val_base,\n                                                                       rmse_val_LR0)"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["### Visualization : Training error"],"metadata":{}},{"cell_type":"code","source":["norm = Normalize()\nclrs = cmap(np.asarray(norm(np.log(error_train_LR0))))[:,0:3]\n\nfig, ax = prepare_plot(np.arange(0, 60, 10), np.arange(2, 6, 1))\nax.set_ylim(2, 6)\nplt.scatter(range(0, num_iters), np.log(error_train_LR0), s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\nax.set_xlabel('Iteration'), ax.set_ylabel(r'$\\log_e(errorTrainLR0)$')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["norm = Normalize()\nclrs = cmap(np.asarray(norm(error_train_LR0[6:])))[:,0:3]\n\nfig, ax = prepare_plot(np.arange(0, 60, 10), np.arange(17, 22, 1))\nax.set_ylim(17.8, 21.2)\nplt.scatter(range(0, num_iters-6), error_train_LR0[6:], s=14**2, c=clrs, edgecolors='#888888', alpha=0.75)\nax.set_xticklabels(map(str, range(6, 66, 10)))\nax.set_xlabel('Iteration'), ax.set_ylabel(r'Training Error')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["## Part 4: Train using SparkML and perform grid search"],"metadata":{}},{"cell_type":"markdown","source":["###  `LinearRegression`"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.regression import LinearRegression\n# Values to use when training the linear regression model\n\nnum_iters = 500  # iterations\nreg = 1e-1  # regParam\nalpha = .2  # elasticNetParam\nuse_intercept = True  # intercept"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["lin_reg = LinearRegression(maxIter=num_iters,regParam=reg,elasticNetParam=alpha,fitIntercept=use_intercept)\nfirst_model = lin_reg.fit(parsed_train_data_df)\n\n# coeffsLR1 stores the model coefficients; interceptLR1 stores the model intercept\ncoeffs_LR1 = first_model.coefficients\nintercept_LR1 = first_model.intercept\nprint coeffs_LR1, intercept_LR1"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":["### (4b) Transform\n\nUsing the [LinearRegressionModel.transform()](https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.regression.LinearRegressionModel.transform) method to make predictions\non the `parsed_train_data_df`."],"metadata":{}},{"cell_type":"code","source":["sample_prediction = first_model.transform(parsed_train_data_df)\ndisplay(sample_prediction)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["###  Evaluating RMSE"],"metadata":{}},{"cell_type":"code","source":["val_pred_df = first_model.transform(parsed_val_data_df)\nrmse_val_LR1 = calc_RMSE(val_pred_df)\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}' +\n       '\\n\\tLR1 = {2:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["###  Grid search"],"metadata":{}},{"cell_type":"code","source":["best_RMSE = rmse_val_LR1\nbest_reg_param = reg\nbest_model = first_model\n\nnum_iters = 500  # iterations\nalpha = .2  # elasticNetParam\nuse_intercept = True  # intercept\n\nfor reg in [1e-10,1e-5,1.0]:\n    lin_reg = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha, fitIntercept=use_intercept)\n    model = lin_reg.fit(parsed_train_data_df)\n    val_pred_df = model.transform(parsed_val_data_df)\n\n    rmse_val_grid = calc_RMSE(val_pred_df)\n    print rmse_val_grid\n\n    if rmse_val_grid < best_RMSE:\n        best_RMSE = rmse_val_grid\n        best_reg_param = reg\n        best_model = model\n\nrmse_val_LR_grid = best_RMSE\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n' +\n       '\\tLRGrid = {3:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1, rmse_val_LR_grid)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"markdown","source":["### Visualization : Best model's predictions"],"metadata":{}},{"cell_type":"code","source":["parsed_val_df = best_model.transform(parsed_val_data_df)\npredictions = np.asarray(parsed_val_df\n                         .select('prediction')\n                         .collect())\nactual = np.asarray(parsed_val_df\n                      .select('label')\n                      .collect())\nerror = np.asarray(parsed_val_df\n                     .rdd\n                     .map(lambda lp: squared_error(lp.label, lp.prediction))\n                     .collect())\n\nnorm = Normalize()\nclrs = cmap(np.asarray(norm(error)))[:,0:3]\n\nfig, ax = prepare_plot(np.arange(0, 120, 20), np.arange(0, 120, 20))\nax.set_xlim(15, 82), ax.set_ylim(-5, 105)\nplt.scatter(predictions, actual, s=14**2, c=clrs, edgecolors='#888888', alpha=0.75, linewidths=.5)\nax.set_xlabel('Predicted'), ax.set_ylabel(r'Actual')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":["### Visualization 6: Hyperparameter heat map"],"metadata":{}},{"cell_type":"code","source":["from matplotlib.colors import LinearSegmentedColormap\n\n# Saved parameters and results, to save the time required to run 36 models\nnum_iters = 500\nreg_params = [1.0, 2.0, 4.0, 8.0, 16.0, 32.0]\nalpha_params = [0.0, .1, .2, .4, .8, 1.0]\nrmse_val = np.array([[ 15.317156766552452, 15.327211561989827, 15.357152971253697, 15.455092206273847, 15.73774335576239,\n                       16.36423857334287, 15.315019185101972, 15.305949211619886, 15.355590337955194, 15.573049001631558,\n                       16.231992712117222, 17.700179790697746, 15.305266383061921, 15.301104931027034, 15.400125020566225,\n                       15.824676190630191, 17.045905140628836, 19.365558346037535, 15.292810983243772, 15.333756681057828,\n                       15.620051033979871, 16.631757941340428, 18.948786862836954, 20.91796910560631, 15.308301384150049,\n                       15.522394576046239, 16.414106221093316, 18.655978799189178, 20.91796910560631, 20.91796910560631,\n                       15.33442896030322, 15.680134490745722, 16.86502909075323, 19.72915603626022, 20.91796910560631,\n                       20.91796910560631 ]])\n\nnum_rows, num_cols = len(alpha_params), len(reg_params)\nrmse_val = np.array(rmse_val)\nrmse_val.shape = (num_rows, num_cols)\n\nfig, ax = prepare_plot(np.arange(0, num_cols, 1), np.arange(0, num_rows, 1), figsize=(8, 7), hideLabels=True,\n                       gridWidth=0.)\nax.set_xticklabels(reg_params), ax.set_yticklabels(alpha_params)\nax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Alpha')\n\ncolors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\nimage = plt.imshow(rmse_val,interpolation='nearest', aspect='auto',\n                    cmap = colors)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["alpha_params_zoom, reg_params_zoom = alpha_params[1:5], reg_params[:4]\nrmse_val_zoom = rmse_val[1:5, :4]\n\nnum_rows, num_cols = len(alpha_params_zoom), len(reg_params_zoom)\n\nfig, ax = prepare_plot(np.arange(0, num_cols, 1), np.arange(0, num_rows, 1), figsize=(8, 7), hideLabels=True,\n                       gridWidth=0.)\nax.set_xticklabels(reg_params_zoom), ax.set_yticklabels(alpha_params_zoom)\nax.set_xlabel('Regularization Parameter'), ax.set_ylabel('Alpha')\n\ncolors = LinearSegmentedColormap.from_list('blue', ['#0022ff', '#000055'], gamma=.2)\nimage = plt.imshow(rmse_val_zoom, interpolation='nearest', aspect='auto',\n                    cmap = colors)\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["## Add interactions between features"],"metadata":{}},{"cell_type":"markdown","source":["### (5a) Add 2-way interactions\n\nSo far, we've used the features as they were provided.  Now, we will add features that capture the two-way interactions between our existing features.  The `two_way_interactions` takes in a `LabeledPoint` and generates a new `LabeledPoint` that contains the old features and the two-way interactions between them."],"metadata":{}},{"cell_type":"code","source":["import itertools\n\ndef two_way_interactions(lp):\n    \"\"\"Creates a new `LabeledPoint` that includes two-way interactions.\n\n    Note:\n        For features [x, y] the two-way interactions would be [x^2, x*y, y*x, y^2] and these\n        would be appended to the original [x, y] feature list.\n\n    Args:\n        lp (LabeledPoint): The label and features for this observation.\n\n    Returns:\n        LabeledPoint: The new `LabeledPoint` should have the same label as `lp`.  Its features\n            should include the features from `lp` followed by the two-way interaction features.\n    \"\"\"\n    r = list((x for x in itertools.product(lp.features, repeat=2)))\n    y=[]\n    for x in lp.features:\n      y.append(x)\n    for i in range(len(r)):\n      c=float(np.dot(r[i][0], r[i][1]))\n      y.append(c)\n    \n    \n    return LabeledPoint(lp.label,y)\n\nprint two_way_interactions(LabeledPoint(0.0, [2, 3]))\n\n# Transforming the existing train, validation, and test sets to include two-way interactions.\ntrain_data_interact_df = parsed_train_data_df.map(lambda l:two_way_interactions(l)).toDF()\nval_data_interact_df = parsed_val_data_df.map(lambda l:two_way_interactions(l)).toDF()\ntest_data_interact_df = parsed_test_data_df.map(lambda l:two_way_interactions(l)).toDF()"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"markdown","source":["###  Building an interaction model"],"metadata":{}},{"cell_type":"code","source":["num_iters = 500\nreg = 1e-10\nalpha = .2\nuse_intercept = True\n\nlin_reg = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha, fitIntercept=use_intercept)\nmodel_interact = lin_reg.fit(train_data_interact_df)\npreds_and_labels_interact_df = model_interact.transform(val_data_interact_df)\nrmse_val_interact = calc_RMSE(preds_and_labels_interact_df)\n\nprint ('Validation RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLR0 = {1:.3f}\\n\\tLR1 = {2:.3f}\\n\\tLRGrid = ' +\n       '{3:.3f}\\n\\tLRInteract = {4:.3f}').format(rmse_val_base, rmse_val_LR0, rmse_val_LR1,\n                                                 rmse_val_LR_grid, rmse_val_interact)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["### (5c) Evaluating interaction model on test data"],"metadata":{}},{"cell_type":"code","source":["preds_and_labels_test_df = model_interact.transform(test_data_interact_df)\nrmse_test_interact = calc_RMSE(preds_and_labels_test_df)\n\nprint ('Test RMSE:\\n\\tBaseline = {0:.3f}\\n\\tLRInteract = {1:.3f}'\n       .format(rmse_test_base, rmse_test_interact))"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":["###  Using a pipeline to create the interaction model"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import PolynomialExpansion\n\nnum_iters = 500\nreg = 1e-10\nalpha = .2\nuse_intercept = True\n\npolynomial_expansion = PolynomialExpansion(degree=2, inputCol='features', outputCol='polyFeatures')\nlinear_regression = LinearRegression(maxIter=num_iters, regParam=reg, elasticNetParam=alpha,\n                                     fitIntercept=use_intercept, featuresCol='polyFeatures')\n\npipeline = Pipeline(stages=[polynomial_expansion,linear_regression])\npipeline_model = pipeline.fit(parsed_train_data_df)\n\npredictions_df = pipeline_model.transform(parsed_test_data_df)\n\nevaluator = RegressionEvaluator()\nrmse_test_pipeline = evaluator.evaluate(predictions_df, {evaluator.metricName: \"rmse\"})\nprint('RMSE for test data set using pipelines: {0:.3f}'.format(rmse_test_pipeline))"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":60}],"metadata":{"name":"cs120_lab2_linear_regression_df","notebookId":1234573087669614},"nbformat":4,"nbformat_minor":0}
